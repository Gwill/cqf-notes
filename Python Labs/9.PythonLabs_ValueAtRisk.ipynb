{"nbformat": 4, "nbformat_minor": 1, "cells": [{"metadata": {}, "source": ["\n<p><img align=\"left\" src=\"https://www.cqf.com/themes/custom/creode/logo.svg\" style=\"vertical-align: top; padding-top: 23px;\" width=\"10%\"/>\n<img align=\"right\" src=\"https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg\" style=\"vertical-align: middle;\" width=\"12%\"/>\n<font color=\"#306998\"><h1><center>Python Labs</center></h1></font></p>\n<p></p><h1><center>Value At Risk</center></h1>\n<center><b>Kannan Singaravelu</b></center>\n<center>kannan.singaravelu@fitchlearning.com</center>\n"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n<h2 id=\"Value-at-Risk\">Value-at-Risk<a class=\"anchor-link\" href=\"#Value-at-Risk\">\u00b6</a></h2><p>Value at Risk - <strong>VaR</strong> - is one of the most important metrics that is used to measures the risk associated with a financial position or a portfolio of financial instruments. VaR can be defined as <strong><code>the maximum loss with a confidence level over a predetermined period.</code></strong> Let's say that the 1-day 95% VaR of our portfolio is $\\$100$. This means that 95% of the time, it is expected that - under normal market conditions - we will not lose more than $100 by holding our portfolio over one day.</p>\n<p>Three approaches that are commonly used in the industry are</p>\n<ul>\n<li><strong>Parametric</strong></li>\n<li><strong>Historical Simulation</strong> </li>\n<li><strong>Monte Carlo Simulation</strong></li>\n</ul>\n"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n<h3 id=\"Import-Libraries\">Import Libraries<a class=\"anchor-link\" href=\"#Import-Libraries\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nimport pandas as pd\nimport numpy as np\nfrom numpy.linalg import multi_dot\n\nfrom scipy.stats import norm\nfrom tabulate import tabulate\n\nimport matplotlib.pyplot as plt\nfrom helper import plot_var \n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Retrieve-Data\">Retrieve Data<a class=\"anchor-link\" href=\"#Retrieve-Data\">\u00b6</a></h3><p>We will use the FAANG stocks as before to build for calculation of VaR</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Load locally stored data\ndf = pd.read_csv('data/faang_stocks.csv', parse_dates=True, index_col=0)['2013':]\n\n# Check first 5 values \ndf.head()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Calculate-Returns\">Calculate Returns<a class=\"anchor-link\" href=\"#Calculate-Returns\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Calculate daily returns\nreturns = df.pct_change().dropna()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\n# Visualize AMZN daily returns\nplt.plot(returns['AMZN'], color='orange')\nplt.axhline(y=0.10, ls='dotted', color='black')\nplt.axhline(y=-0.10, ls='dotted', color='black')\nplt.title('AMZN Daily Returns')\nplt.grid(True)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Parametric-VaR\">Parametric VaR<a class=\"anchor-link\" href=\"#Parametric-VaR\">\u00b6</a></h3><p>The Variance-covariance is a parametric method which assumes (almost always) that the returns are normally distributed. In this method, we first calculate the mean and standard deviation of the returns to derive the risk metric. Based on the assumption of normality, we can generalise,</p>\n$$ VaR = position * (\\mu_{period} - z * \\sigma_p) $$<table>\n<thead><tr>\n<th style=\"text-align:left\">Confidence Level</th>\n<th style=\"text-align:left\">Value At Risk     </th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"><code>90%</code></td>\n<td style=\"text-align:left\">$\\mu$ - $1.29$ * $\\sigma$ </td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>95%</code></td>\n<td style=\"text-align:left\">$\\mu$ - $1.64$ * $\\sigma$             </td>\n</tr>\n<tr>\n<td style=\"text-align:left\"><code>99%</code></td>\n<td style=\"text-align:left\">$\\mu$ - $2.33$ * $\\sigma$             </td>\n</tr>\n</tbody>\n</table>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Calculate mean and standard deviation \nmean = np.mean(returns['AMZN'])\nstdev = np.std(returns['AMZN'])\n\n# Calculate VaR at difference confidence level\nVaR_90 = norm.ppf(1-0.90,mean,stdev)\nVaR_95 = norm.ppf(1-0.95,mean,stdev) #norm.ppf(0.05)\nVaR_99 = norm.ppf(1-0.99,mean,stdev)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\n# Ouput results in tabular format\ntable = [['90%', VaR_90],['95%', VaR_95],['99%', VaR_99] ]\nheader = ['Confidence Level', 'Value At Risk']\nprint(tabulate(table,headers=header))\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<p>Lets now define a VaR function so that we can use it calculate it for individual stocks</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# VaR function\ndef VaR(symbol, cl=0.95):\n    mean = np.mean(returns[symbol])\n    stdev = np.std(returns[symbol])\n    \n    return np.around(100*norm.ppf(1-cl,mean,stdev),4)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\n# VaR for stocks\nprint('VaR for FAANG Stocks')\nprint('---'*11)\n[print(f'VaR at 95% CL for {stock:4} : {VaR(stock)}%') for stock in df.columns][0]\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\n# Visulalize VaR at 95% confidence level\nplot_var()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<p>Now, let's assume that we have 1,000 shares of AMZN's stock on April 29, 2020. What is the maximum loss next day with a confidence level of 99%?</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nnum_of_shares = 1000\nprice = df['AMZN'].iloc[-1]\nposition = num_of_shares * price \n\namzn_var = position * VaR_99\n\nprint(f'Amazon Holding Value: {position}')\nprint(f'Amazon VaR at 99% confidence level is: {amzn_var}')\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<p>VaR can also be calculated using the above formula at 99% confidence level.</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# VaR calculation by appling direct formulae\nposition * (mean + norm.ppf(1-0.99) * stdev)         # mean-2.33*stdev\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Scaling-VaR\">Scaling VaR<a class=\"anchor-link\" href=\"#Scaling-VaR\">\u00b6</a></h3><p>Now, let's calculate VaR over a 5-day period. To scale it, multiply by square root of time.</p>\n$$ VaR = position * (\\mu_{period} - z * \\sigma_p) * \\sqrt{T}$$\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\nforecast_days = 5\nf_VaR_90 = VaR_90*np.sqrt(forecast_days)\nf_VaR_95 = VaR_95*np.sqrt(forecast_days)\nf_VaR_99 = VaR_99*np.sqrt(forecast_days)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nftable = [['90%', f_VaR_90],['95%', f_VaR_95],['99%', f_VaR_99] ]\nfheader = ['Confidence Level', '5-Day Forecast Value At Risk']\nprint(tabulate(ftable,headers=fheader))\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<p>Let's now calculate AMZN VaR over a 5-day period with a confidence level of 99%</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\namzn_var_5days = position * f_VaR_99\n\nprint(f'Amazon Holding Value: {position}')\nprint(f'Amazon VaR at 99% confidence level is: {amzn_var_5days}')\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\n# Scaled VaR over different time horizon\nplt.figure(figsize=(8,6))\nplt.plot(range(100),[-100*VaR_95*np.sqrt(x) for x in range(100)])\nplt.xlabel('Horizon')\nplt.ylabel('Var 95 (%)')\nplt.title('VaR_95 Scaled by Time');\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Historical-VaR\">Historical VaR<a class=\"anchor-link\" href=\"#Historical-VaR\">\u00b6</a></h3><p>Asset returns do not necessarily follow a normal distribution. An alternative is to use sorted returns to evaluate a VaR. This method uses historical data where returns are sorted in ascending order to calculate maximum possible loss for a given confidence level.</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Use quantile function for Historical VaR\nhVaR_90 = returns['AMZN'].quantile(0.10)\nhVaR_95 = returns['AMZN'].quantile(0.05)\nhVaR_99 = returns['AMZN'].quantile(0.01)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nhtable = [['90%', hVaR_90],['95%', hVaR_95],['99%', hVaR_99]]\nprint(tabulate(htable,headers=header))\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n<h3 id=\"Expected-Short-Fall\">Expected Short Fall<a class=\"anchor-link\" href=\"#Expected-Short-Fall\">\u00b6</a></h3><p>VaR is a reasonable measure of risk if assumption of normality holds. Else, we might underestimate the risk if we observe a fat tail or overestimate the risk if tail is thinner. Expected shortfall or Conditional Value at Risk - <strong>CVaR</strong> - is an estimate of expected shortfall sustained in the worst 1 - x% of scenarios. It is defined as the average loss based on the returns that are lower than the VaR threshold. Assume that we have <code>n</code> return observations, then the expected shortfall is</p>\n$$ CVaR = \\frac 1 n * \\sum_{i=1}^{n} R_i[R&lt;hVaR_{cl}]$$<p>where, $R$ is returns, $hVaR$ is historical VaR and $cl$ is the confidence level.</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Calculate CVar\nCVaR_90 = returns['AMZN'][returns['AMZN']<=hVaR_90].mean()\nCVaR_95 = returns['AMZN'][returns['AMZN']<=hVaR_95].mean()\nCVaR_99 = returns['AMZN'][returns['AMZN']<=hVaR_99].mean()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nctable = [['90%', CVaR_90],['95%', CVaR_95],['99%', CVaR_99] ]\ncheader = ['Confidence Level', 'Conditional Value At Risk']\nprint(tabulate(ctable,headers=cheader))\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"MonteCarlo-VaR\">MonteCarlo VaR<a class=\"anchor-link\" href=\"#MonteCarlo-VaR\">\u00b6</a></h3><p>The Monte Carlo simulation approach has a number of similarities to historical simulation. It allows us to use actual historical distributions rather than having to assume normal returns. As returns are assumed to follow a normal distribution, we could generate <em><code>n</code></em> simulated returns with the same mean and standard deviation (derived from the daily returns) and then sorted in ascending order to calculate maximum possible loss for a given confidence level.</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Set seed for reproducibility\nnp.random.seed(12345)\n\n# Number of simulations\nn_sims = 5000\n\n# Simulate returns and sort\nsim_returns = np.random.normal(mean, stdev, n_sims)\n\n# Use percentile function for MCVaR\nMCVaR_90 = np.percentile(sim_returns,10)\nMCVaR_95 = np.percentile(sim_returns, 5)\nMCVaR_99 = np.percentile(sim_returns,1)\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nmctable = [['90%', MCVaR_90],['95%', MCVaR_95],['99%', MCVaR_99]]\nprint(tabulate(mctable,headers=header))\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h2 id=\"Portfolio-VaR\">Portfolio VaR<a class=\"anchor-link\" href=\"#Portfolio-VaR\">\u00b6</a></h2>\n"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n<h3 id=\"Assign-Weights\">Assign Weights<a class=\"anchor-link\" href=\"#Assign-Weights\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Assign random weights\n# np.random.seed(40)\n# wts = np.random.random((5,1))\nwts = np.array([0.2,0.2,0.2,0.2,0.2])[:,np.newaxis]\nwts\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Portfolio-return\">Portfolio return<a class=\"anchor-link\" href=\"#Portfolio-return\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Stock returns\nreturns[:5]\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nport_ret = np.dot(returns,wts)\nport_ret.flatten()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\nport_mean = port_ret.mean()\nport_mean\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Portfolio-Volatility\">Portfolio Volatility<a class=\"anchor-link\" href=\"#Portfolio-Volatility\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Covariance matrix\nreturns.cov()\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\n# Portfolio volatility\nport_stdev = np.sqrt(multi_dot([wts.T, returns.cov(), wts]))\nport_stdev.flatten()[0]\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Portfolio-Position\">Portfolio Position<a class=\"anchor-link\" href=\"#Portfolio-Position\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Portfolio Position\nport_pos = (df.iloc[-1] * num_of_shares).sum()\nport_pos\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\n# Calculate Portfolio VaR at difference confidence level\npVaR_90 = norm.ppf(1-0.90,port_mean,port_stdev).flatten()[0]\npVaR_95 = norm.ppf(1-0.95,port_mean,port_stdev).flatten()[0]\npVaR_99 = norm.ppf(1-0.99,port_mean,port_stdev).flatten()[0]\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "outputs": [], "source": ["\npVaR_95\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<h3 id=\"Portfolio-VaR\">Portfolio VaR<a class=\"anchor-link\" href=\"#Portfolio-VaR\">\u00b6</a></h3>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Ouput results in tabular format\nptable = [['90%', pVaR_90],['95%', pVaR_95],['99%', pVaR_99]]\nheader = ['Confidence Level', 'Value At Risk']\nprint(tabulate(ptable,headers=header))\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<p>Let's now compare the portfolio VaR numbers with that of the individual stocks</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["\n# Iterate over symbols\nfor stock in df.columns:\n    pos = df[stock].iloc[-1] * num_of_shares\n    pvar = pos * VaR(stock)\n    \n    print(f'{stock} Holding Value: {pos:0.4}') \n    print(f'{stock} VaR at 95% confidence level: {pvar:0.4}')\n    print()\n\nprint(f'Portfolio Holding Value: {port_pos:0.4}')\nprint(f'Portoflio VaR at 95% confidence level is: {port_pos * pVaR_95:0.4}')\n\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {}, "source": ["\n<p>The VaR for the current portfolio of $\\$ 4.6$ million is \\$109,356, which is much lesser than the individual VaR numbers. This signifies the effect of diversification by selecting different stocks.</p>\n"], "cell_type": "markdown"}, {"metadata": {}, "source": ["\n<h1 id=\"References\">References<a class=\"anchor-link\" href=\"#References\">\u00b6</a></h1><ul>\n<li><p>Numpy documentation <a href=\"https://docs.scipy.org/doc/numpy/\">https://docs.scipy.org/doc/numpy/</a></p>\n</li>\n<li><p>Scipy documentation <a href=\"https://docs.scipy.org/doc/scipy/reference/\">https://docs.scipy.org/doc/scipy/reference/</a></p>\n</li>\n</ul>\n"], "cell_type": "markdown"}], "metadata": {}}